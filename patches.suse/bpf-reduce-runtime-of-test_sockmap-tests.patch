From: John Fastabend <john.fastabend@gmail.com>
Date: Tue, 24 Apr 2018 16:28:18 -0700
Subject: bpf: reduce runtime of test_sockmap tests
Patch-mainline: v4.18-rc1
Git-commit: a18fda1a62c3313685ec222802d5b6743dbd560e
References: bsc#1109837

When test_sockmap was running outside of selftests and was not being
run by build bots it was reasonable to spend significant amount of
time running various tests. The number of tests is high because many
different I/O iterators are run.

However, now that test_sockmap is part of selftests rather than
iterate through all I/O sides only test a minimal set of min/max
values along with a few "normal" I/O ops. Also remove the long
running tests. They can be run from other test frameworks on a regular
cadence.

This significanly reduces runtime of test_sockmap.

Before:

$ time sudo ./test_sockmap  > /dev/null

real    4m47.521s
user    0m0.370s
sys     0m3.131s

After:

$ time sudo ./test_sockmap  > /dev/null

real    0m0.514s
user    0m0.104s
sys     0m0.430s

The CLI is still available for users that want to test the long
running tests that do the larger send/recv tests.

Signed-off-by: John Fastabend <john.fastabend@gmail.com>
Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Acked-by: Thomas Bogendoerfer <tbogendoerfer@suse.de>
---
 tools/testing/selftests/bpf/test_sockmap.c |   33 ++++++++++++++---------------
 1 file changed, 16 insertions(+), 17 deletions(-)

--- a/tools/testing/selftests/bpf/test_sockmap.c
+++ b/tools/testing/selftests/bpf/test_sockmap.c
@@ -344,8 +344,8 @@ static int msg_loop(int fd, int iov_coun
 		if (err < 0)
 			perror("recv start time: ");
 		while (s->bytes_recvd < total_bytes) {
-			timeout.tv_sec = 1;
-			timeout.tv_usec = 0;
+			timeout.tv_sec = 0;
+			timeout.tv_usec = 10;
 
 			/* FD sets */
 			FD_ZERO(&w);
@@ -903,12 +903,10 @@ static int test_exec(int cgrp, struct so
 {
 	int err = __test_exec(cgrp, SENDMSG, opt);
 
-	sched_yield();
 	if (err)
 		goto out;
 
 	err = __test_exec(cgrp, SENDPAGE, opt);
-	sched_yield();
 out:
 	return err;
 }
@@ -928,19 +926,18 @@ static int test_loop(int cgrp)
 	opt.iov_length = 0;
 	opt.rate = 0;
 
-	for (r = 1; r < 100; r += 33) {
-		for (i = 1; i < 100; i += 33) {
-			for (l = 1; l < 100; l += 33) {
-				opt.rate = r;
-				opt.iov_count = i;
-				opt.iov_length = l;
-				err = test_exec(cgrp, &opt);
-				if (err)
-					goto out;
-			}
+	r = 1;
+	for (i = 1; i < 100; i += 33) {
+		for (l = 1; l < 100; l += 33) {
+			opt.rate = r;
+			opt.iov_count = i;
+			opt.iov_length = l;
+			err = test_exec(cgrp, &opt);
+			if (err)
+				goto out;
 		}
 	}
-
+	sched_yield();
 out:
 	return err;
 }
@@ -1031,6 +1028,7 @@ static int test_send(struct sockmap_opti
 	if (err)
 		goto out;
 out:
+	sched_yield();
 	return err;
 }
 
@@ -1168,7 +1166,7 @@ static int test_start_end(int cgrp)
 	opt.iov_length = 100;
 	txmsg_cork = 1600;
 
-	for (i = 99; i <= 1600; i += 100) {
+	for (i = 99; i <= 1600; i += 500) {
 		txmsg_start = 0;
 		txmsg_end = i;
 		err = test_exec(cgrp, &opt);
@@ -1177,7 +1175,7 @@ static int test_start_end(int cgrp)
 	}
 
 	/* Test start/end with cork but pull data in middle */
-	for (i = 199; i <= 1600; i += 100) {
+	for (i = 199; i <= 1600; i += 500) {
 		txmsg_start = 100;
 		txmsg_end = i;
 		err = test_exec(cgrp, &opt);
@@ -1221,6 +1219,7 @@ static int test_start_end(int cgrp)
 out:
 	txmsg_start = 0;
 	txmsg_end = 0;
+	sched_yield();
 	return err;
 }
 
