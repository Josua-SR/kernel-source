From: Ben Skeggs <bskeggs@redhat.com>
Date: Wed, 1 Nov 2017 03:56:19 +1000
Subject: drm/nouveau: wrap nvkm_mem objects in nvkm_memory interfaces
Git-commit: bd275f1d1a982db62edcd22f3aebf6253583ea37
Patch-mainline: v4.15-rc1
References: FATE#326289 FATE#326079 FATE#326049 FATE#322398 FATE#326166

This is a transition step, to enable finer-grained commits while
transitioning to new MMU interfaces.

Signed-off-by: Ben Skeggs <bskeggs@redhat.com>
Acked-by: Petr Tesarik <ptesarik@suse.com>
---
 drivers/gpu/drm/nouveau/include/nvkm/subdev/fb.h    |    3 +
 drivers/gpu/drm/nouveau/nouveau_mem.c               |   33 ++++++++++++++++++++
 drivers/gpu/drm/nouveau/nouveau_mem.h               |    7 ++++
 drivers/gpu/drm/nouveau/nvkm/subdev/fb/ram.c        |    1 
 drivers/gpu/drm/nouveau/nvkm/subdev/instmem/gk20a.c |    9 +++++
 5 files changed, 53 insertions(+)

--- a/drivers/gpu/drm/nouveau/include/nvkm/subdev/fb.h
+++ b/drivers/gpu/drm/nouveau/include/nvkm/subdev/fb.h
@@ -1,6 +1,7 @@
 #ifndef __NVKM_FB_H__
 #define __NVKM_FB_H__
 #include <core/subdev.h>
+#include <core/memory.h>
 
 #include <subdev/mmu.h>
 
@@ -29,6 +30,8 @@ struct nvkm_mem {
 	u64 offset;
 	u64 size;
 	struct sg_table *sg;
+
+	struct nvkm_memory *memory;
 };
 
 struct nvkm_fb_tile {
--- a/drivers/gpu/drm/nouveau/nouveau_mem.c
+++ b/drivers/gpu/drm/nouveau/nouveau_mem.c
@@ -66,6 +66,7 @@ nouveau_mem_host(struct ttm_mem_reg *reg
 	else            mem->__mem.pages = tt->dma_address;
 	mem->_mem = &mem->__mem;
 	mem->mem.page = 12;
+	mem->_mem->memory = &mem->memory;
 	return 0;
 }
 
@@ -78,6 +79,7 @@ nouveau_mem_vram(struct ttm_mem_reg *reg
 	int ret;
 
 	mem->mem.page = page;
+	mem->_mem->memory = &mem->memory;
 
 	ret = ram->func->get(ram, size, 1 << page, contig ? 0 : 1 << page,
 			     (mem->comp << 8) | mem->kind, &mem->_mem);
@@ -97,6 +99,36 @@ nouveau_mem_del(struct ttm_mem_reg *reg)
 	reg->mm_node = NULL;
 }
 
+static enum nvkm_memory_target
+nouveau_mem_memory_target(struct nvkm_memory *memory)
+{
+	struct nouveau_mem *mem = container_of(memory, typeof(*mem), memory);
+	if (mem->_mem->mem)
+		return NVKM_MEM_TARGET_VRAM;
+	return NVKM_MEM_TARGET_HOST;
+};
+
+static u8
+nouveau_mem_memory_page(struct nvkm_memory *memory)
+{
+	struct nouveau_mem *mem = container_of(memory, typeof(*mem), memory);
+	return mem->mem.page;
+};
+
+static u64
+nouveau_mem_memory_size(struct nvkm_memory *memory)
+{
+	struct nouveau_mem *mem = container_of(memory, typeof(*mem), memory);
+	return mem->_mem->size << 12;
+}
+
+static const struct nvkm_memory_func
+nouveau_mem_memory = {
+	.target = nouveau_mem_memory_target,
+	.page = nouveau_mem_memory_page,
+	.size = nouveau_mem_memory_size,
+};
+
 int
 nouveau_mem_new(struct nouveau_cli *cli, u8 kind, u8 comp,
 		struct ttm_mem_reg *reg)
@@ -108,6 +140,7 @@ nouveau_mem_new(struct nouveau_cli *cli,
 	mem->cli = cli;
 	mem->kind = kind;
 	mem->comp = comp;
+	nvkm_memory_ctor(&nouveau_mem_memory, &mem->memory);
 
 	reg->mm_node = mem;
 	return 0;
--- a/drivers/gpu/drm/nouveau/nouveau_mem.h
+++ b/drivers/gpu/drm/nouveau/nouveau_mem.h
@@ -23,6 +23,13 @@ struct nouveau_mem {
 	struct nvkm_mem __mem;
 	struct nvkm_mem *_mem;
 	struct nvkm_vma bar_vma;
+
+	struct nvkm_memory memory;
+};
+
+enum nvif_vmm_get {
+	PTES,
+	LAZY,
 };
 
 int nouveau_mem_new(struct nouveau_cli *, u8 kind, u8 comp,
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ram.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ram.c
@@ -41,6 +41,7 @@ nvkm_vram_map(struct nvkm_memory *memory
 	struct nvkm_vram *vram = nvkm_vram(memory);
 	struct nvkm_mem mem = {
 		.mem = vram->mn,
+		.memory = &vram->memory,
 	};
 	nvkm_vm_map_at(vma, offset, &mem);
 	return 0;
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/instmem/gk20a.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/instmem/gk20a.c
@@ -119,6 +119,12 @@ gk20a_instobj_target(struct nvkm_memory
 	return NVKM_MEM_TARGET_NCOH;
 }
 
+static u8
+gk20a_instobj_page(struct nvkm_memory *memory)
+{
+	return 12;
+}
+
 static u64
 gk20a_instobj_addr(struct nvkm_memory *memory)
 {
@@ -343,6 +349,7 @@ static const struct nvkm_memory_func
 gk20a_instobj_func_dma = {
 	.dtor = gk20a_instobj_dtor_dma,
 	.target = gk20a_instobj_target,
+	.page = gk20a_instobj_page,
 	.addr = gk20a_instobj_addr,
 	.size = gk20a_instobj_size,
 	.acquire = gk20a_instobj_acquire_dma,
@@ -354,6 +361,7 @@ static const struct nvkm_memory_func
 gk20a_instobj_func_iommu = {
 	.dtor = gk20a_instobj_dtor_iommu,
 	.target = gk20a_instobj_target,
+	.page = gk20a_instobj_page,
 	.addr = gk20a_instobj_addr,
 	.size = gk20a_instobj_size,
 	.acquire = gk20a_instobj_acquire_iommu,
@@ -531,6 +539,7 @@ gk20a_instobj_new(struct nvkm_instmem *b
 	/* present memory for being mapped using small pages */
 	node->mem.size = size >> 12;
 	node->mem.memtype = 0;
+	node->mem.memory = &node->memory;
 
 	nvkm_debug(subdev, "alloc size: 0x%x, align: 0x%x, gaddr: 0x%llx\n",
 		   size, align, node->mem.offset);
